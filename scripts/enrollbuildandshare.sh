# enroll, build, and share (ebs.sh)
Enroll creates a single gra.ph ID, however, it should also have an embedded logic, like  a prefix for a business, and a geo location ID and a language and  topic coding. The builds should all flow for fastest processing. The sharing should have a priority. Social first, adjacent topics second, and serendipitous third, and obvious extensions fourth.
# enroll new users
At a certain point, we should create a new user profile if the search is distinct enough. Not a second data capture, just a recognition that the graph is far enough apart from a prior seeded graph that it should not generate the same Social, adjacent, and obvious extensions....
# authenticate via FB, LinkedIn, or Twitter
Authenticate and offer a chance for the user to disambiguate (under the $1.99 subscription model) at this time
# create user id & account
Account is already created, what I vision is the the ID is begining to be created as the data and the seed terms are ranked and processed
# capture user inpht re seeds
Original data and second pass data and permissioned data fromm the social sites and their profiles
# analyze and assemble user provided seeds

# build user provided seeds
Match with system provided obvious seed packages (SEED--music, top 40,....SEED PACKAGE---list of top 40 songs for the week, match all artists on the list, provide play list for each artist)

# harvest graphs from FB, LinkedIn, Twitter
Is this occuring after the creation of the ID? Or is this part of the creation of an ID for a graph?
	#FB

	#LinkedIn

	#Twitter

# carry out entity extraction and analysis against
Donâ€™t  do all of the analysis at the start. Cache it and deliver the analysis in 5 minutes. Allow the first couple of graphs to fill, and then provide the follow on. The user experience will look for a natural feedback, so new input will continually refine the graph, I bet that practiced users will be looking for a higher order build, and will appreciate the lag as it will allow for a refinement of the seed terms.
	#FB

	#LinkedIn

	#Twitter

# is it better to harvest all at once, then analyze all at once, or to harvest & extract one at a time? Following the above logic, harvest and extract one ata time, allowing for a superior build. User will begin to chose which to harvest first, and will guide for a better harvest and extraction with practice. This will become part of the user ID (say use FB first for my son and Linked In for me)


# analyze and assemble list of graph provided seeds

# compare graph provided seeds to user provided seeds, eliminate duplicates
Will the same seeds provide identical results if they search in slightly different data pools or in a different sequence? Before we eliminate dups, we should ask if the customer wants all dups searched in different sequences...etc.
# should user provided seeds trump? not necessarily ...
Provide all, until the user profile suggests a preference
# build graph provided seeds

# when all (most?) builds are complete ...
Not sure. Good question. Needs data on the user experience. 
# share all/most graphs
Same as above
